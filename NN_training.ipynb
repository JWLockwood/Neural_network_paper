{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6acd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "WLseries1001_1600.mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb90d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Load Packages ##############\n",
    "\n",
    "from scipy.io import netcdf\n",
    "import numpy as np   \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt  # Python standard library datetime  module\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from PermutationImportance import sklearn_permutation_importance\n",
    "from PyALE import ale\n",
    "from tune_sklearn import TuneSearchCV\n",
    "from tune_sklearn import TuneGridSearchCV\n",
    "import scipy\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy import stats\n",
    "import scipy.io\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "###### Set up the font sizes for matplotlib ######\n",
    "FONT_SIZE = 14\n",
    "BIG_FONT_SIZE = FONT_SIZE + 2\n",
    "LARGE_FONT_SIZE = FONT_SIZE + 4\n",
    "HUGE_FONT_SIZE = FONT_SIZE + 6\n",
    "SMALL_FONT_SIZE = FONT_SIZE - 2\n",
    "TINY_FONT_SIZE = FONT_SIZE - 4\n",
    "TEENSIE_FONT_SIZE = FONT_SIZE - 6\n",
    "font_sizes = {\n",
    "    'teensie': TEENSIE_FONT_SIZE,\n",
    "    'tiny': TINY_FONT_SIZE,\n",
    "    'small': SMALL_FONT_SIZE,\n",
    "    'normal': FONT_SIZE,\n",
    "    'big': BIG_FONT_SIZE,\n",
    "    'large': LARGE_FONT_SIZE,\n",
    "    'huge': HUGE_FONT_SIZE,\n",
    "}\n",
    "plt.rc('font', size=FONT_SIZE)\n",
    "plt.rc('axes', titlesize=FONT_SIZE)\n",
    "plt.rc('axes', labelsize=FONT_SIZE)\n",
    "plt.rc('xtick', labelsize=TINY_FONT_SIZE)\n",
    "plt.rc('ytick', labelsize=TINY_FONT_SIZE)\n",
    "plt.rc('legend', fontsize=FONT_SIZE)\n",
    "plt.rc('figure', titlesize=BIG_FONT_SIZE)\n",
    "\n",
    "###### Define plot importance metric #########\n",
    "def plot_variable_importance(importance_obj, filename, multipass=True, relative=False, num_vars_to_plot=10, diagnostics=0):\n",
    "    \"\"\"Plots any variable importance method for a particular estimator\n",
    "    :param importance_obj: ImportanceResult object returned by PermutationImportance\n",
    "    :param filename: string to place the file into (including directory and '.png')\n",
    "    :param multipxass: whether to plot multipass or singlepass results. Default to True\n",
    "    :param relative: whether to plot the absolute value of the results or the results relative to the original. Defaults\n",
    "        to plotting the absolute results\n",
    "    :param num_vars_to_plot: number of top variables to actually plot (cause otherwise it won't fit)\n",
    "    :param diagnostics: 0 for no printouts, 1 for all printouts, 2 for some printouts. defaults to 0\n",
    "    \"\"\"\n",
    "\n",
    "    rankings = importance_obj.retrieve_multipass(\n",
    "    ) if multipass else importance_obj.retrieve_singlepass()\n",
    "\n",
    "    original_score = importance_obj.original_score\n",
    "\n",
    "    try:\n",
    "        len(original_score)\n",
    "    except:\n",
    "        bootstrapped = False\n",
    "    else:\n",
    "        bootstrapped = True\n",
    "\n",
    "    if bootstrapped:\n",
    "        original_score_mean = np.mean(original_score)\n",
    "    else:\n",
    "        original_score_mean = original_score\n",
    "\n",
    "    # Sort by increasing rank\n",
    "    sorted_var_names = list(rankings.keys())\n",
    "    sorted_var_names.sort(key=lambda k: rankings[k][0])\n",
    "    sorted_var_names = sorted_var_names[:min(num_vars_to_plot, len(rankings))]\n",
    "    scores = [rankings[var][1] for var in sorted_var_names]\n",
    "\n",
    "    colors_to_plot = [variable_to_color(var) for var in [\n",
    "        \"Original Score\", ] + sorted_var_names]\n",
    "    variable_names_to_plot = [\" {}\".format(\n",
    "        var) for var in convert_vars_to_readable([\"Original Score\", ] + sorted_var_names)]\n",
    "\n",
    "    if bootstrapped:\n",
    "        if relative:\n",
    "            scores_to_plot = np.array([original_score_mean, ] + [np.mean(score)\n",
    "                                                                 for score in scores]) / original_score_mean\n",
    "        else:\n",
    "            scores_to_plot = np.array(\n",
    "                [original_score_mean, ] + [np.mean(score) for score in scores])\n",
    "        ci = np.array([np.abs(np.mean(score) - np.percentile(score, [0.025, 0.975]))\n",
    "                       for score in np.r_[[original_score, ], scores]]).transpose()\n",
    "    else:\n",
    "        if relative:\n",
    "            scores_to_plot = np.array(\n",
    "                [original_score_mean, ] + scores) / original_score_mean\n",
    "        else:\n",
    "            scores_to_plot = np.array(\n",
    "                [original_score_mean, ] + scores)\n",
    "        ci = np.array([[0, 0]\n",
    "                       for score in np.r_[[original_score, ], scores]]).transpose()\n",
    "\n",
    "    metric = \"Score\"\n",
    "    if importance_obj.method == \"Permutation Importance\":\n",
    "        method = \"%s Permutation Importance\" % (\n",
    "            \"Multipass\" if multipass else \"Singlepass\")\n",
    "    else:\n",
    "        method = importance_obj.method\n",
    "    title = \"%s\\n%s\" % (metric, method)\n",
    "\n",
    "    # Actually make plot\n",
    "    fig = plt.figure(figsize=(4, 3))\n",
    "    if bootstrapped:\n",
    "        plt.barh(np.arange(len(scores_to_plot)),\n",
    "                 scores_to_plot, linewidth=1, edgecolor='black', color=colors_to_plot, xerr=ci, capsize=4, ecolor='grey', error_kw=dict(alpha=0.4))\n",
    "    else:\n",
    "        plt.barh(np.arange(len(scores_to_plot)),\n",
    "                 scores_to_plot, linewidth=1, edgecolor='black', color=colors_to_plot)\n",
    "\n",
    "    # Put the variable names _into_ the plot\n",
    "    for i in range(len(variable_names_to_plot)):\n",
    "        plt.text(0, i, variable_names_to_plot[i],\n",
    "                 va=\"center\", ha=\"left\", size=font_sizes['teensie'])\n",
    "    if relative:\n",
    "        plt.axvline(1, linestyle=':', color='grey')\n",
    "        plt.text(1, len(variable_names_to_plot) / 2, \"original score = %0.3f\" % original_score_mean,\n",
    "                 va='center', ha='left', size=font_sizes['teensie'], rotation=270)\n",
    "        plt.xlabel(\"Percent of Original Score\")\n",
    "        plt.xlim([0, 1.2])\n",
    "    else:\n",
    "        plt.axvline(original_score_mean, linestyle=':', color='grey')\n",
    "        plt.text(original_score_mean, len(variable_names_to_plot) / 2, \"original score\",\n",
    "                 va='center', ha='left', size=font_sizes['teensie'], rotation=270)\n",
    "        plt.xlabel(\"Score\")\n",
    "\n",
    "    plt.ylabel(\"Predictor Permuted\")\n",
    "    plt.title(title)\n",
    "    plt.yticks([])\n",
    "    plt.gca().xaxis.set_major_formatter(FormatStrFormatter('%.3f'))\n",
    "\n",
    "    # make the horizontal plot go with the highest value at the top\n",
    "    plt.gca().invert_yaxis()\n",
    "\n",
    "    print(\"Saving file to %s\" % filename)\n",
    "    plt.savefig(filename, dpi=300, bbox_inches=\"tight\")\n",
    "    \n",
    "    \n",
    "# You can fill this in by using a dictionary with {var_name: legible_name}\n",
    "def convert_vars_to_readable(variables_list):\n",
    "    \"\"\"Substitutes out variable names for human-readable ones\n",
    "    :param variables_list: a list of variable names\n",
    "    :returns: a copy of the list with human-readable names\n",
    "    \"\"\"\n",
    "    human_readable_list = list()\n",
    "    for var in variables_list:\n",
    "        if False:  # var in VARIABLE_NAMES_DICTONARY:\n",
    "            pass  # human_readable_list.append(VARIABLE_NAMES_DICTONARY[var])\n",
    "        else:\n",
    "            human_readable_list.append(var)\n",
    "    return human_readable_list\n",
    "\n",
    "\n",
    "# This could easily be expanded with a dictionary\n",
    "def variable_to_color(var):\n",
    "    return \"lightblue\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a61240",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "##########################################\n",
    "############# Start NN deve ##############\n",
    "######### Author JWLocwkwood  ############\n",
    "######### Date last mod 10 June 2021  ####\n",
    "##########################################\n",
    "\n",
    "fname = \"WATERLEVELS/saving_tracks/loc_200_all3_again/site_\" + str(v) + \"_tracks.mat\" # File to read\n",
    "x = scipy.io.loadmat(fname)\n",
    "### Load input, output ###\n",
    "levels2 = (x['levels22']) \n",
    "lon10022 = (x['lon10022'])\n",
    "vstore22 = (x['vstore22'])\n",
    "lat10022 = (x['lat10022'])\n",
    "rostore22 = (x['rostore22'])\n",
    "speed10022 = (x['speed10022'])\n",
    "pstore10022 = (x['pstore10022'])\n",
    "bearing10022 = (x['bearing10022'])\n",
    "\n",
    "# Need to scale and df \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
    "\n",
    "# Fit and predict model \n",
    "history = best_mlp.fit(X_trains,y_trains)\n",
    "y_pred = best_mlp.predict(X_tests)\n",
    "\n",
    "####### LOOP through each tracks, scros for mse and then save MSE,RMSE,CORR,R2 and best parameters, and test train\n",
    "for v in np.arange(1):\n",
    "    vv = a1[v]\n",
    "    v=vv\n",
    "    fname = \"/Data/r300_d300/site_\" + str(v) + \"_tracks.mat\" # File to read\n",
    "    x = scipy.io.loadmat(fname)\n",
    "    disatnce22 = (x['disatnce22'])\n",
    "    levels2 = (x['levels2'])\n",
    "    lon10022 = (x['lon10022'])\n",
    "    vstore22 = (x['vstore22'])\n",
    "    lat10022 = (x['lat10022'])\n",
    "    rostore22 = (x['rostore22'])\n",
    "    rmw10022 = (x['rmw10022'])\n",
    "    speed10022 = (x['speed10022'])\n",
    "    disatnce22 = (x['disatnce22'])\n",
    "    pstore10022 = (x['pstore10022'])\n",
    "    bearing10022 = (x['bearing10022'])\n",
    "    pstore1002grad2 = (x['pstore1002grad2'])\n",
    "    vstore1002grad2 = (x['vstore1002grad2'])\n",
    "\n",
    "    abc = (np.shape(levels2))\n",
    "    abc = (abc[0])\n",
    "    all_data = np.empty([8,abc])\n",
    "    all_data[0,:] = bearing10022[:,0]\n",
    "    all_data[1,:] = rmw10022[:,0]\n",
    "    all_data[2,:] = speed10022[:,0]\n",
    "    all_data[3,:] = vstore22[:,0]\n",
    "    all_data[4,:] = rostore22[:,0]\n",
    "    all_data[5,:] = pstore10022[:,0]\n",
    "    all_data[6,:] = lon10022[:,0] \n",
    "    all_data[7,:] = lat10022[:,0] \n",
    "\n",
    "    y = np.asarray(levels2)\n",
    "    X = np.asarray(all_data.T)\n",
    "    y = np.asarray(levels2)\n",
    "    X = np.asarray(all_data.T)\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = MinMaxScaler()\n",
    "    X_trains = scaler.fit_transform(X_train)\n",
    "    scaler = MinMaxScaler()\n",
    "    X_tests = scaler.fit_transform(X_test)\n",
    "    scaler = MinMaxScaler()\n",
    "    y_trains = scaler.fit_transform(y_train)\n",
    "    scaler = MinMaxScaler()\n",
    "    y_tests = scaler.fit_transform(y_test)\n",
    "\n",
    "    estimator = MLPRegressor()\n",
    "    param_grid = {'hidden_layer_sizes': [(100,200,100),(200, 200, 200),(200,100),(100,200,300),(200,300,300),(120,100)]}\n",
    "    \n",
    "    # Testing the hyperparameters #\n",
    "    from sklearn.metrics import make_scorer\n",
    "    mse = make_scorer(mean_squared_error,greater_is_better=False)\n",
    "    gsc = TuneGridSearchCV(estimator, param_grid, scoring=mse, max_iters=5)\n",
    "    grid_result = gsc.fit(X_trains, y_trains)\n",
    "    best_params = grid_result.best_params_\n",
    "    best_mlp = MLPRegressor(hidden_layer_sizes = best_params[\"hidden_layer_sizes\"], activation = \"relu\", solver=\"adam\", max_iter = 1000, n_iter_no_change = 400, batch_size = 100)\n",
    "    history = best_mlp.fit(X_trains,y_trains)\n",
    "    y_pred = best_mlp.predict(X_tests)\n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
